---
title: "Regresiones para tesis"
output: html_notebook
---

# Cargamos librerías

```{r include=FALSE}
library(tidyverse)
library(spdep)
```

# Cargamos datos

```{r}
# data grifos
grifos_sc <-
  readRDS(here::here("data", "processed", "grifos_con_sc_razon_social.RDS"))

# cargamos los precios para 2017 de DB5
rutas_fuel <- list(
  here::here("data", "processed", "data_diesel_mensual.rds"),
  here::here("data", "processed", "data_g90_mensual.rds")
)

data_precios <- map(
  rutas_fuel,
  ~ readRDS(.x) %>%
    filter(
      `año` >= 2017,
      codigo_de_osinergmin %in% grifos_sc$codigo_de_osinergmin
    ) %>%
    mutate(dia = 1) %>%
    unite(fecha, dia, mes, `año`, sep = "-", remove = FALSE) %>%
    select(-dia) %>%
    filter(
      mes != 13,
      precio_de_venta > 6
    )
)


precios_db5 <- data_precios[[1]]

precios_g90 <- data_precios[[2]]

# cargamos data de distritos

data_distrital_raw <- read_csv(here::here("data", "demo-distrital", "data_pop_lima.csv")) %>%
  janitor::clean_names()
```
## Limpiamos archivo distrital:

```{r}
data_distrital_clean <- data_distrital_raw %>%
  rename(
    "pop_2017" = poblacion_total_30_06_2017,
    "densidad_2017" = densidad_poblacional_hab_km2,
    "ingresos_2012" = ingreso_per_capita
  ) %>%
  mutate(
    pop_2017 = str_remove(pop_2017, " ") %>% parse_number(),
    densidad_2017 = str_remove(densidad_2017, " ") %>% parse_number(),
    distrito = str_to_upper(distrito)
  )
```


## Creamos archivos con info
```{r}
grifos_sc <- grifos_sc %>%
  mutate(
    serv_mecanico = if_else(mecanico + aceite + llanteria > 0, 1, 0),
    serv_mecanico = as.factor(serv_mecanico)
  ) %>%
  mutate(
    num_grifos_cerc = if_else(is.na(num_grifos_cerc), as.integer(0), num_grifos_cerc),
    distancia_avg = if_else(is.na(distancia_avg), 0, distancia_avg)
  )


data_total <- map(
  list(precios_db5, precios_g90),
  ~ left_join(grifos_sc, .x, by = "codigo_de_osinergmin") %>%
    left_join(., data_distrital_clean, by = "distrito")
)

data_db5 <- data_total[[1]]
data_g90 <- data_total[[2]]
```


# Primera regresión OLS pooled

Hacemos una regresión OLS pooled, clusterizando a nivel de grifo, en corte transversal para un periodo.



```{r}


data <- data_db5 %>%
  filter(mes == 1, `año` == 2017) %>%
  select(
    precio_de_venta,
    tipo_bandera,
    sc_pre,
    distancia_avg,
    distancia_min,
    num_grifos_cerc,
    serv_mecanico,
    lavado,
    cajero,
    con_gnv,
    con_glp,
    ingresos_2012,
    densidad_2017,
    lat,
    lon,
    codigo_de_osinergmin
  ) %>%
  drop_na()

modelo_data <- lm(data %>% select(-lat, -lon, -codigo_de_osinergmin))


summary(modelo_data)
```
Test de Moran
```{r}
coords <- cbind(data$lon, data$lat)

grifos <- data$codigo_de_osinergmin

grifos_nb <- tri2nb(coords, row.names = grifos)

sp_grifos <- nb2listw(grifos_nb)


LMtest <- lm.LMtests(modelo_data, sp_grifos, test = "all")
LMtest
```

Aparentemente, el modelo con lag es el significativo, así que usaremos ese. Estiamos el modelo espacial de Durbin:

```{r}
modelo <- precio_de_venta ~ tipo_bandera +
  sc_pre +
  distancia_avg +
  distancia_min +
  num_grifos_cerc +
  serv_mecanico +
  lavado +
  cajero +
  con_gnv +
  con_glp +
  ingresos_2012 +
  densidad_2017
durbin_model <- lagsarlm(modelo,
  data = data,
  listw = sp_grifos,
  Durbin = TRUE
)

summary(durbin_model)
```

Corremos el modelo de rezagos espaciales:

```{r}
spa_lag_model <- lagsarlm(formula = modelo, data = data, listw = sp_grifos)
summary(spa_lag_model)
```

```{r}
LR.sarlm(durbin_model, spa_lag_model)
```
```{r}
summary(spa_lag_model)
```

# Corremos los modelos OLS para todos los meses antes de la compra

```{r func-regresiones}
# Funcion para output de regresiones

output_reg <- function(data, modelo) {
  data_mes_nest <- data %>%
    select(
      precio_de_venta,
      tipo_bandera,
      sc_pre,
      sc_post,
      distancia_avg,
      distancia_min,
      num_grifos_cerc,
      serv_mecanico,
      lavado,
      cajero,
      con_gnv,
      con_glp,
      ingresos_2012,
      densidad_2017,
      lat,
      lon,
      codigo_de_osinergmin,
      mes,
      `año`
    ) %>%
    group_by(mes, `año`) %>%
    nest()

  data_mes_model <- data_mes_nest %>%
    mutate(ols = map(data, ~ lm(modelo, data = .x)))



  list1 <- as.list(select(data_mes_model, ols, mes, `año`))


  out <- capture.output(pwalk(
    list1,
    function(ols, mes, `año`) {
      cat("Mes: ", mes, "Año: ", `año`, "\n\n")
      print(summary(ols))
    }
  ))

  out
}
```


```{r full-model}
modelo <- precio_de_venta ~ tipo_bandera +
  sc_pre +
  distancia_avg +
  distancia_min +
  num_grifos_cerc +
  serv_mecanico +
  lavado +
  cajero +
  con_gnv +
  con_glp +
  ingresos_2012 +
  densidad_2017



out_db5 <- output_reg(data_db5, modelo)
out_g90 <- output_reg(data_g90, modelo)

cat("Output de OLS", out_db5, file = here::here("data", "text-output", "summary_ols_full_db5.txt"), sep = "\n", append = FALSE)
cat("Output de OLS", out_db5, file = here::here("data", "text-output", "summary_ols_full_g90.txt"), sep = "\n", append = FALSE)
```



Ahora simplificamos oLS con variables significativas para DB5 y G90


```{r simp-model}
modelo <- precio_de_venta ~ tipo_bandera +
  distancia_avg +
  distancia_min +
  num_grifos_cerc +
  serv_mecanico +
  lavado +
  cajero +
  con_gnv +
  con_glp +
  ingresos_2012



out_g90 <- output_reg(data_g90, modelo)
out_db5 <- output_reg(data_db5, modelo)
cat("Output de OLS", out_db5, file = here::here("data", "text-output", "summary_ols_usando_simp_db5.txt"), sep = "\n", append = FALSE)
cat("Output de OLS", out_g90, file = here::here("data", "text-output", "summary_ols_usando_simp_g90.txt"), sep = "\n", append = FALSE)
```

# Test de Morga

Primero vemos si es necesario utilizar rezagos espaciales, para eso utilizamos el
test de I-morgan

```{r}


data <- data_db5 %>%
  filter(mes == 1, `año` == 2017) %>%
  select(
    precio_de_venta,
    tipo_bandera,
    sc_pre,
    distancia_avg,
    distancia_min,
    num_grifos_cerc,
    serv_mecanico,
    lavado,
    cajero,
    con_gnv,
    con_glp,
    ingresos_2012,
    densidad_2017,
    lat,
    lon,
    codigo_de_osinergmin
  ) %>%
  drop_na()

modelo_data <- lm(data %>% select(-lat, -lon, -codigo_de_osinergmin))


summary(modelo_data)
coords <- cbind(data$lon, data$lat)

grifos <- data$codigo_de_osinergmin

grifos_nb <- tri2nb(coords, row.names = grifos)

sp_grifos <- nb2listw(grifos_nb)


LMtest <- lm.LMtests(modelo_data, sp_grifos, test = "all")
LMtest
```

```{r}
calcular_reg_month <- function(data) {
  data_mes_nest <- data %>%
    select(
      precio_de_venta,
      tipo_bandera,
      sc_pre,
      sc_post,
      distancia_avg,
      distancia_min,
      num_grifos_cerc,
      serv_mecanico,
      lavado,
      cajero,
      con_gnv,
      con_glp,
      ingresos_2012,
      densidad_2017,
      lat,
      lon,
      codigo_de_osinergmin,
      mes,
      `año`
    ) %>%
    group_by(mes, `año`) %>%
    nest()

  data_mes_model <- data_mes_nest %>%
    mutate(
      ols = map(data, ~ lm(modelo, data = .x)),
      coords = map(data, ~ cbind(.x$lon, .x$lat)),
      grifos = map(data, ~ .x$codigo_de_osinergmin),
      grifos_nb = map2(coords, grifos, ~ tri2nb(.x, row.names = .y)),
      sp_grifos = map(grifos_nb, ~ nb2listw(.x)),
      spatial_lag = map2(data, sp_grifos, ~ lagsarlm(modelo, data = .x, listw = .y)),
      durbin = map2(data, sp_grifos, ~ lagsarlm(modelo, data = .x, listw = .y, Durbin = TRUE)),
      test_LR = map2(durbin, spatial_lag, ~ LR.sarlm(.x, .y)),
      LMtest = map2(ols, sp_grifos, ~ lm.LMtests(.x, .y, test = "all"))
    )
  data_mes_model
}
```

Evaluamos para DB5
```{r}
db5_all_models_tests <- calcular_reg_month(data_db5)

list_var <- db5_all_models_tests %>%
  select(test_LR, mes, `año`) %>%
  as.list()

out_var <- capture.output(pwalk(
  list_var,
  function(test_LR, mes, `año`) {
    cat("Mes: ", mes, "Año: ", `año`, "\n\n")
    print(test_LR)
  }
))

cat("Output test LR",
  out_var,
  file = here::here("data", "text-output", "summary_test_LR_db5.txt"), sep = "\n", append = FALSE
)
```


```{r}

list_var <- db5_all_models_tests %>%
  select(spatial_lag, mes, `año`) %>%
  as.list()

out_var <- capture.output(pwalk(
  list_var,
  function(spatial_lag, mes, `año`) {
    cat("Mes: ", mes, "Año: ", `año`, "\n\n")
    print(summary(spatial_lag))
  }
))

cat("Output Spatial Lag",
  out_var,
  file = here::here("data", "text-output", "summary_spatial_lag_db5.txt"), sep = "\n", append = FALSE
)
```

Evaluamos para G90
```{r}
db5_all_models_tests <- calcular_reg_month(data_g90)

list_var <- db5_all_models_tests %>%
  select(test_LR, mes, `año`) %>%
  as.list()

out_var <- capture.output(pwalk(
  list_var,
  function(test_LR, mes, `año`) {
    cat("Mes: ", mes, "Año: ", `año`, "\n\n")
    print(test_LR)
  }
))

cat("Output test LR",
  out_var,
  file = here::here("data", "text-output", "summary_test_LR_g90.txt"), sep = "\n", append = FALSE
)
```


```{r}

list_var <- db5_all_models_tests %>%
  select(spatial_lag, mes, `año`) %>%
  as.list()

out_var <- capture.output(pwalk(
  list_var,
  function(spatial_lag, mes, `año`) {
    cat("Mes: ", mes, "Año: ", `año`, "\n\n")
    print(summary(spatial_lag))
  }
))

cat("Output Spatial Lag",
  out_var,
  file = here::here("data", "text-output", "summary_spatial_lag_g90.txt"), sep = "\n", append = FALSE
)
```

# Regresión de efectos fijos

Realizamos un modelo de efectos fijos a nivel de estación y en el tiempo


Primero debemos crear una variable que sea `COMPRADA` igual a 1 si si la estación la compró Primax, 0 lo contrario. Es decir, hasta Diciembre es 0 para todos, y luego 1 solo para las propias PECSA. Otra variable `vecino_comprado` si el grifo i tiene en su vecindad un grifo comprado por Primax. 


## Primero solo con variable comprada para estaciones PECSA
```{r}
data_db5 %>%
  mutate(
    COMPRADA = case_when(
      `año` == 2017 ~ 0,
      tipo_bandera == "PROPIA PECSA" ~ 1,
      TRUE ~ 0
    ),
    fecha = lubridate::dmy(fecha)
  ) -> data_db5_comprada
```


### Corremos regresión efectos fijos

Primero solo con 
```{r}
library(multiwayvcov)
library(lmtest)
library(plm)
pdf <- pdata.frame(data_db5_comprada %>% drop_na(), index = c("codigo_de_osinergmin", "fecha"))

modelo <- precio_de_venta ~
COMPRADA

model <- plm(modelo, data = pdf, model = "within", effect = "twoways")

summary(model)

# Cluster by firm
coeftest(model, vcov = vcovHC(model, type = "sss", cluster = "group"))
```

### Exportamos data a stata para hacer lo mismo

```{r}
library(readstata13)
data_db5 %>%
  mutate(COMPRADA = case_when(
    `año` == 2017 ~ 0,
    tipo_bandera == "PROPIA PECSA" ~ 1,
    TRUE ~ 0
  )) %>%
  write.csv(file = here::here("data", "processed", "data_diesel_reg_comprada.csv"))
```

## Añadamos variables de competencia de estaciones cercanas:

Cargamos archivo con vecinos de Thiessen y generamos dataframe con datos e indicador si tiene vecino pecsa

```{r}
grifos_vecinos <- readRDS(here::here("data", "processed", "grifo_con_vecinos_pre.RDS"))

vecinos_pecsa_thissen <- grifos_vecinos %>%
  group_by(codigo_de_osinergmin.princ) %>%
  mutate(vecino_pecsa_thiessen = if_else(str_detect(razon_social.vec, "PERUANA DE ESTACIONES"),
    1,
    0
  )) %>%
  arrange(codigo_de_osinergmin.princ, desc(vecino_pecsa_thiessen)) %>%
  distinct(codigo_de_osinergmin.princ, .keep_all = TRUE) %>%
  select(codigo_de_osinergmin.princ, vecino_pecsa_thiessen) 

```
Ahora calculemos los vecinos 
